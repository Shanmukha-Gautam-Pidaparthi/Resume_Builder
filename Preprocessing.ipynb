{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "a1b2c3d4",
            "metadata": {},
            "source": [
                "# Data Preprocessing for RAG-based AI Resume Builder\n",
                "\n",
                "This notebook preprocesses the Kaggle **Resume.csv** dataset (Snehaan Bhawal) for ingestion into ChromaDB.\n",
                "\n",
                "**Pipeline Steps:**\n",
                "1. Load the dataset\n",
                "2. Clean the `Resume_str` column (strip HTML tags, special characters, normalise whitespace)\n",
                "3. Chunk text using `RecursiveCharacterTextSplitter` (chunk_size=1000, overlap=200)\n",
                "4. Format output as a list of dictionaries with `id`, `content`, and `metadata`\n",
                "\n",
                "**Constraints:** Only `pandas`, `re`, and `langchain` are used."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "e5f6g7h8",
            "metadata": {},
            "source": [
                "## 1. Imports & Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "i9j0k1l2",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "All imports loaded successfully.\n"
                    ]
                }
            ],
            "source": [
                "import json\n",
                "import os\n",
                "import re\n",
                "\n",
                "import pandas as pd\n",
                "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
                "\n",
                "print(\"All imports loaded successfully.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "m3n4o5p6",
            "metadata": {},
            "source": [
                "## 2. Load the Dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "q7r8s9t0",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loading dataset from: ../archive(7)/Resume/Resume.csv\n",
                        "Total rows loaded: 2484\n",
                        "Columns: ['ID', 'Resume_str', 'Resume_html', 'Category']\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>ID</th>\n",
                            "      <th>Resume_str</th>\n",
                            "      <th>Resume_html</th>\n",
                            "      <th>Category</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>16852973</td>\n",
                            "      <td>HR ADMINISTRATOR/MARKETING ASSOCIATE\\...</td>\n",
                            "      <td>&lt;div class=\"fontsize fontface vmargins hmargin...</td>\n",
                            "      <td>HR</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>22323967</td>\n",
                            "      <td>HR SPECIALIST, US HR OPERATIONS      ...</td>\n",
                            "      <td>&lt;div class=\"fontsize fontface vmargins hmargin...</td>\n",
                            "      <td>HR</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "         ID                                         Resume_str  \\\n",
                            "0  16852973           HR ADMINISTRATOR/MARKETING ASSOCIATE\\...   \n",
                            "1  22323967           HR SPECIALIST, US HR OPERATIONS      ...   \n",
                            "\n",
                            "                                         Resume_html Category  \n",
                            "0  <div class=\"fontsize fontface vmargins hmargin...       HR  \n",
                            "1  <div class=\"fontsize fontface vmargins hmargin...       HR  "
                        ]
                    },
                    "execution_count": 2,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Update this path if your Resume.csv is in a different location\n",
                "CSV_PATH = os.path.join(\"..\", \"archive(7)\", \"Resume\", \"Resume.csv\")\n",
                "CSV_PATH = os.path.normpath(CSV_PATH)\n",
                "\n",
                "print(f\"Loading dataset from: {CSV_PATH}\")\n",
                "df = pd.read_csv(CSV_PATH)\n",
                "print(f\"Total rows loaded: {len(df)}\")\n",
                "print(f\"Columns: {list(df.columns)}\")\n",
                "df.head(2)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "u1v2w3x4",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Rows after dropping nulls: 2484\n",
                        "Unique categories (24): ['HR', 'DESIGNER', 'INFORMATION-TECHNOLOGY', 'TEACHER', 'ADVOCATE', 'BUSINESS-DEVELOPMENT', 'HEALTHCARE', 'FITNESS', 'AGRICULTURE', 'BPO', 'SALES', 'CONSULTANT', 'DIGITAL-MEDIA', 'AUTOMOBILE', 'CHEF', 'FINANCE', 'APPAREL', 'ENGINEERING', 'ACCOUNTANT', 'CONSTRUCTION', 'PUBLIC-RELATIONS', 'BANKING', 'ARTS', 'AVIATION']\n"
                    ]
                }
            ],
            "source": [
                "# Drop rows where Resume_str is null\n",
                "df = df.dropna(subset=[\"Resume_str\"])\n",
                "print(f\"Rows after dropping nulls: {len(df)}\")\n",
                "print(f\"Unique categories ({df['Category'].nunique()}): {df['Category'].unique().tolist()}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "y5z6a7b8",
            "metadata": {},
            "source": [
                "## 3. Data Cleaning\n",
                "\n",
                "The `clean_text` function performs three cleaning steps:\n",
                "1. **Strip HTML tags** — using `re.sub(r'<[^>]+>', ' ', text)`\n",
                "2. **Remove special characters** — keep only letters, digits, and basic punctuation (`. , ; : ! ? - '`)\n",
                "3. **Normalise whitespace** — collapse multiple spaces/newlines into a single space"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "c9d0e1f2",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "clean_text function defined.\n"
                    ]
                }
            ],
            "source": [
                "def clean_text(text: str) -> str:\n",
                "    \"\"\"Clean a raw resume string.\n",
                "\n",
                "    Steps:\n",
                "        1. Remove all HTML tags.\n",
                "        2. Remove special characters (keep letters, digits, basic punctuation).\n",
                "        3. Collapse multiple whitespace / newlines into a single space.\n",
                "        4. Strip leading and trailing whitespace.\n",
                "\n",
                "    Args:\n",
                "        text: Raw resume string, potentially containing HTML fragments.\n",
                "\n",
                "    Returns:\n",
                "        Cleaned, normalised plain-text string.\n",
                "    \"\"\"\n",
                "    if not isinstance(text, str):\n",
                "        return \"\"\n",
                "\n",
                "    # Strip HTML tags\n",
                "    text = re.sub(r\"<[^>]+>\", \" \", text)\n",
                "\n",
                "    # Keep only alphanumeric characters, whitespace, and basic punctuation\n",
                "    text = re.sub(r\"[^a-zA-Z0-9\\s\\.\\,\\;\\:\\!\\?\\-\\']\", \" \", text)\n",
                "\n",
                "    # Normalise whitespace (spaces, tabs, newlines) to single space\n",
                "    text = re.sub(r\"\\s+\", \" \", text)\n",
                "\n",
                "    return text.strip()\n",
                "\n",
                "\n",
                "print(\"clean_text function defined.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "g3h4i5j6",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Cleaning Resume_str column ...\n",
                        "Done!\n",
                        "\n",
                        "Sample cleaned text (first 500 chars):\n",
                        "HR ADMINISTRATOR MARKETING ASSOCIATE HR ADMINISTRATOR Summary Dedicated Customer Service Manager with 15 years of experience in Hospitality and Customer Service Management. Respected builder and leader of customer-focused teams; strives to instill a shared, enthusiastic commitment to customer service. Highlights Focused on customer satisfaction Team management Marketing savvy Conflict resolution techniques Training and development Skilled multi-tasker Client relations specialist Accomplishments \n"
                    ]
                }
            ],
            "source": [
                "# Apply cleaning to the Resume_str column\n",
                "print(\"Cleaning Resume_str column ...\")\n",
                "df[\"Resume_str\"] = df[\"Resume_str\"].apply(clean_text)\n",
                "print(\"Done!\\n\")\n",
                "\n",
                "# Preview a cleaned resume\n",
                "print(\"Sample cleaned text (first 500 chars):\")\n",
                "print(df[\"Resume_str\"].iloc[0][:500])"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "k7l8m9n0",
            "metadata": {},
            "source": [
                "## 4. Text Chunking\n",
                "\n",
                "We use LangChain's `RecursiveCharacterTextSplitter` with:\n",
                "- **chunk_size = 1000** characters\n",
                "- **chunk_overlap = 200** characters\n",
                "\n",
                "This maintains semantic context across chunk boundaries, ensuring that when ChromaDB retrieves a chunk for a user query, the surrounding context is preserved."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "o1p2q3r4",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "chunk_and_format function defined.\n"
                    ]
                }
            ],
            "source": [
                "def chunk_and_format(df: pd.DataFrame) -> list:\n",
                "    \"\"\"Split cleaned resumes into chunks and format for ChromaDB ingestion.\n",
                "\n",
                "    Each chunk is returned as a dictionary with:\n",
                "        - id:       \"<original_ID>_chunk_<index>\"\n",
                "        - content:  the cleaned text chunk\n",
                "        - metadata: {\"Category\": \"<original_category>\"}\n",
                "\n",
                "    Args:\n",
                "        df: DataFrame with columns ID, Resume_str (cleaned), and Category.\n",
                "\n",
                "    Returns:\n",
                "        List of dictionaries ready for vector-database ingestion.\n",
                "    \"\"\"\n",
                "    splitter = RecursiveCharacterTextSplitter(\n",
                "        chunk_size=1000,\n",
                "        chunk_overlap=200,\n",
                "    )\n",
                "\n",
                "    results = []\n",
                "\n",
                "    for _, row in df.iterrows():\n",
                "        resume_id = row[\"ID\"]\n",
                "        category = row[\"Category\"]\n",
                "        cleaned_text = row[\"Resume_str\"]\n",
                "\n",
                "        if not cleaned_text:\n",
                "            continue\n",
                "\n",
                "        chunks = splitter.split_text(cleaned_text)\n",
                "\n",
                "        for i, chunk in enumerate(chunks):\n",
                "            results.append(\n",
                "                {\n",
                "                    \"id\": f\"{resume_id}_chunk_{i}\",\n",
                "                    \"content\": chunk,\n",
                "                    \"metadata\": {\"Category\": category},\n",
                "                }\n",
                "            )\n",
                "\n",
                "    return results\n",
                "\n",
                "\n",
                "print(\"chunk_and_format function defined.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "s5t6u7v8",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Chunking text (chunk_size=1000, overlap=200) ...\n",
                        "Total chunks generated: 18893\n"
                    ]
                }
            ],
            "source": [
                "# Run chunking\n",
                "print(\"Chunking text (chunk_size=1000, overlap=200) ...\")\n",
                "preprocessed = chunk_and_format(df)\n",
                "print(f\"Total chunks generated: {len(preprocessed)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "w9x0y1z2",
            "metadata": {},
            "source": [
                "## 5. Results Summary"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "id": "a3b4c5d6",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "============================================================\n",
                        "  Resumes processed : 2484\n",
                        "  Unique categories : 24\n",
                        "  Total chunks      : 18893\n",
                        "============================================================\n"
                    ]
                }
            ],
            "source": [
                "print(\"=\" * 60)\n",
                "print(f\"  Resumes processed : {len(df)}\")\n",
                "print(f\"  Unique categories : {df['Category'].nunique()}\")\n",
                "print(f\"  Total chunks      : {len(preprocessed)}\")\n",
                "print(\"=\" * 60)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "e7f8g9h0",
            "metadata": {},
            "source": [
                "## 6. Sample Output\n",
                "\n",
                "Preview the first few chunks to verify the output format."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "id": "i1j2k3l4",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "{\n",
                        "  \"id\": \"16852973_chunk_0\",\n",
                        "  \"content\": \"HR ADMINISTRATOR MARKETING ASSOCIATE HR ADMINISTRATOR Summary Dedicated Customer Service Manager with 15 years of experience in Hospitality and Customer Service Management. Respected builder and leader of customer-focused teams; strives to instill a shared, enthusiastic commitment to customer service. Highlights Focused on customer satisfaction Team management Marketing savvy Conflict resolution techniques Training and development Skilled multi-tasker Client relations specialist Accomplishments Missouri DOT Supervisor Training Certification Certified by IHG in Customer Loyalty and Marketing by Segment Hilton Worldwide General Manager Training Certification Accomplished Trainer for cross server hospitality systems such as Hilton OnQ , Micros Opera PMS , Fidelio OPERA Reservation System ORS , Holidex Completed courses and seminars in customer service, sales strategies, inventory control, loss prevention, safety, time management, leadership and performance assessment. Experience HR\",\n",
                        "  \"metadata\": {\n",
                        "    \"Category\": \"HR\"\n",
                        "  }\n",
                        "}\n",
                        "----------------------------------------\n",
                        "{\n",
                        "  \"id\": \"16852973_chunk_1\",\n",
                        "  \"content\": \"ORS , Holidex Completed courses and seminars in customer service, sales strategies, inventory control, loss prevention, safety, time management, leadership and performance assessment. Experience HR Administrator Marketing Associate HR Administrator Dec 2013 to Current Company Name City , State Helps to develop policies, directs and coordinates activities such as employment, compensation, labor relations, benefits, training, and employee services. Prepares employee separation notices and related documentation Keeps records of benefits plans participation such as insurance and pension plan, personnel transactions such as hires, promotions, transfers, performance reviews, and terminations, and employee statistics for government reporting. Advises management in appropriate resolution of employee relations issues. Administers benefits programs such as life, health, dental, insurance, pension plans, vacation, sick leave, leave of absence, and employee assistance. Marketing Associate\",\n",
                        "  \"metadata\": {\n",
                        "    \"Category\": \"HR\"\n",
                        "  }\n",
                        "}\n",
                        "----------------------------------------\n",
                        "{\n",
                        "  \"id\": \"16852973_chunk_2\",\n",
                        "  \"content\": \"employee relations issues. Administers benefits programs such as life, health, dental, insurance, pension plans, vacation, sick leave, leave of absence, and employee assistance. Marketing Associate Designed and created marketing collateral for sales meetings, trade shows and company executives. Managed the in-house advertising program consisting of print and media collateral pieces. Assisted in the complete design and launch of the company's website in 2 months. Created an official company page on Facebook to facilitate interaction with customers. Analyzed ratings and programming features of competitors to evaluate the effectiveness of marketing strategies. Advanced Medical Claims Analyst Mar 2012 to Dec 2013 Company Name City , State Reviewed medical bills for the accuracy of the treatments, tests, and hospital stays prior to sanctioning the claims. Trained to interpret the codes ICD-9, CPT and terminology commonly used in medical billing to fully understand the paperwork that is\",\n",
                        "  \"metadata\": {\n",
                        "    \"Category\": \"HR\"\n",
                        "  }\n",
                        "}\n",
                        "----------------------------------------\n"
                    ]
                }
            ],
            "source": [
                "# Display first 3 chunks\n",
                "for entry in preprocessed[:3]:\n",
                "    print(json.dumps(entry, indent=2))\n",
                "    print(\"-\" * 40)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "m5n6o7p8",
            "metadata": {},
            "source": [
                "## 7. Save to JSON\n",
                "\n",
                "Save the preprocessed chunks to `preprocessed_chunks.json` for downstream ChromaDB ingestion."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "id": "q9r0s1t2",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Saved 18893 chunks to preprocessed_chunks.json\n"
                    ]
                }
            ],
            "source": [
                "OUTPUT_PATH = \"preprocessed_chunks.json\"\n",
                "\n",
                "with open(OUTPUT_PATH, \"w\", encoding=\"utf-8\") as f:\n",
                "    json.dump(preprocessed, f, ensure_ascii=False, indent=2)\n",
                "\n",
                "print(f\"Saved {len(preprocessed)} chunks to {OUTPUT_PATH}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "u3v4w5x6",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "In the Preprocessing step, we cleaned the raw Kaggle dataset by removing structural noise (HTML tags and special characters) to improve embedding quality. We then used a Recursive Character Text Splitter to divide resumes into 1000-character chunks with a 200-character (20%) overlap. This ensures that when the user queries for a specific skill, ChromaDB retrieves the most semantically relevant sections rather than irrelevant headers or footers."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "e47f8421",
            "metadata": {},
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
